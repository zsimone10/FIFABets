{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "import numpy as np\n",
    "import requests\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_url = 'https://sofifa.com'\n",
    "\n",
    "ids = {'Manchester City': 3466, 'Chelsea': 3475, 'Liverpool': 3462, \n",
    "       'Manchester United': 3457, 'Tottenham Hotspur': 3470, 'Liverpool': 3459,\n",
    "       'Everton': 3467, 'Burnley': 4234, 'Leicester City': 8021, 'West Ham United': 3463,\n",
    "       'Southampton': 6504, 'Crystal Palace': 7261, 'Watford': 8784, 'Fulham': 3474,\n",
    "       'Newcastle United': 3458, 'Wolverhampton Wanderers': 4225,\n",
    "       'Brighton & Hove Albion': -1, 'Bournemouth': 8779, 'Huddersfield Town': -2, \n",
    "       'Cardiff City': 8344, 'Arsenal': 3459, 'Stoke City': 3472,\n",
    "       'West Bromwich Albion': 3460, 'Swansea City': 5744}\n",
    "       \n",
    "       \n",
    "team_api_ids = {'Manchester City': 8456, 'Chelsea': 8455, 'Liverpool': 8650, \n",
    "                'Manchester United': 10260, 'Tottenham Hotspur': 8586, 'Liverpool': 9825,\n",
    "                'Everton': 8668, 'Burnley': 8191, 'Leicester City': 8197, 'West Ham United': 8654,\n",
    "                'Southampton': 8466, 'Crystal Palace': 9826, 'Watford': 9817, 'Fulham': 9879,\n",
    "                'Newcastle United': 10261, 'Wolverhampton Wanderers': 8602, \n",
    "                'Brighton & Hove Albion': -1, 'Bournemouth': 8678, 'Huddersfield Town': -2, \n",
    "                'Cardiff City': 7276, 'Arsenal': 9825, 'Stoke City': 10194, \n",
    "                'West Bromwich Albion': 8659, 'Swansea City': 10003}\n",
    "\n",
    "column_headers = ['id', 'team_fifa_api_id', 'date', 'buildUpPlaySpeed', 'buildUpPlaySpeedClass',\n",
    "                 'buildUpPlayDribbling', 'buildUpPlayDribblingClass',\n",
    "                 'buildUpPlayPassing', 'buildUpPlayPassingClass', 'buildUpPlayPositioningClass',\n",
    "                 'chanceCreationPassing', 'chanceCreationPassingClass', 'chanceCreationCrossing', \n",
    "                 'chanceCreationCrossingClass',\n",
    "                 'chanceCreationShooting', 'chanceCreationShootingClass',\n",
    "                 'chanceCreationPositioningClass', 'defencePressure', 'defencePressureClass',\n",
    "                 'defenceAggression', 'defenceAggressionClass', 'defenceTeamWidth',\n",
    "                 'defenceTeamWidthClass', 'defenceDefenderLineClass']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def soup_maker(url):\n",
    "    r = requests.get(url)\n",
    "    markup = r.content\n",
    "    soup = bs(markup, 'lxml')\n",
    "    return soup\n",
    "\n",
    "\n",
    "def find_team_links(soup):\n",
    "    table = soup.find('table', {'class': 'table table-hover persist-area'})  # Table of teams\n",
    "    tbody = table.find('tbody')\n",
    "    all_a = tbody.find_all('a', {'class': ''})\n",
    "    return [base_url + link['href'] + year_extension for link in all_a if '/team/' in link['href']]\n",
    "\n",
    "\n",
    "def get_team_attributes(soup):\n",
    "    df_row = pd.DataFrame(columns=column_headers)\n",
    "    info = soup.find('div', {'class': 'info'}).find('h1').text.split('(')\n",
    "    team_name = info[0].strip()\n",
    "    team_fifa_api_id = info[1].split(': ')[1].split(')')[0]\n",
    "    \n",
    "    df_row.loc[0, 'id'] = str(ids[team_name])\n",
    "    df_row.loc[0, 'team_api_id'] = str(team_api_ids[team_name])\n",
    "    df_row.loc[0, 'team_fifa_api_id'] = team_fifa_api_id\n",
    "    \n",
    "    card_div = soup.find('div', {'class': 'card mb-2'})\n",
    "    attributes_div = card_div.find('div', {'class': 'card-body'})\n",
    "    data = attributes_div.find_all('dd')\n",
    "    start = False\n",
    "    i = 3\n",
    "    for datum in data:\n",
    "        category = datum.find('span', {'class': ['tooltip', 'multiline']})\n",
    "        if start or 'Speed' in category.text:\n",
    "            start = True\n",
    "            category = 'Dribbling' if category is None else category.text\n",
    "            vals = datum.find('span', {'class': 'float-right'}).text\n",
    "            if category != 'Positioning' and category != 'Defender Line':\n",
    "                vals = vals.split()\n",
    "            else:\n",
    "                vals = [vals]\n",
    "            for val in vals:\n",
    "                df_row.loc[0, column_headers[i]] = val\n",
    "                i += 1 \n",
    "    return df_row\n",
    "\n",
    "\n",
    "def get_all_team_attributes(team_urls):\n",
    "    team_attrs = pd.DataFrame(columns=column_headers)\n",
    "    for team_url in team_urls:\n",
    "        team_soup = soup_maker(team_url)\n",
    "        df_row = get_team_attributes(team_soup)\n",
    "        team_attrs = team_attrs.append(df_row, ignore_index=True)\n",
    "    return team_attrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "team_attributes = pd.DataFrame(columns=column_headers)\n",
    "years = [2018, 2019]\n",
    "for year in years:\n",
    "    if year == 2018:\n",
    "        year_extension = '?lg%5B0%5D=13&v=18&e=158865&set=true' # BPL Fifa 18, Sept 28 2017\n",
    "        date = '2018-09-28 00:00:00'\n",
    "    elif year == 2019:\n",
    "        year_extension = '?lg%5B0%5D=13&v=19&e=159229&set=true'  # BPL Fifa 19, Sept 27 2018\n",
    "        date = '2019-07-28 00:00:00'\n",
    "        \n",
    "    teams_url = base_url + '/teams' + year_extension\n",
    "    teams_soup = soup_maker(teams_url)\n",
    "    team_urls = find_team_links(teams_soup)\n",
    "    df = get_all_team_attributes(team_urls)\n",
    "    df['date'] = date\n",
    "    team_attributes = team_attributes.append(df, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "desired_cols = ['home_team_goal', 'away_team_goal', 'home_team_api_id', 'away_team_api_id',\n",
    "                  'B365H', 'B365D', 'B365A', 'BWH', 'BWD', 'BWA', 'IWH', 'IWD', 'IWA', 'LBH', 'LBD',\n",
    "                  'LBA', 'PSH', 'PSD', 'PSA', 'WHH', 'WHD', 'WHA', 'SJH', 'SJD', 'SJA', 'VCH', 'VCD',\n",
    "                  'VCA', 'GBH', 'GBD', 'GBA', 'BSH', 'BSD', 'BSA']\n",
    "\n",
    "def clean_odds_data(odds_data):\n",
    "\n",
    "    column_mappings = {'FTHG': 'home_team_goal', 'FTAG': 'away_team_goal'}\n",
    "    odds_data = odds_data.rename(columns=column_mappings)\n",
    "\n",
    "    # Hacky way to find ID in map from abbreviated name\n",
    "    def get_api_id(team_name):\n",
    "        for name, api_id in team_api_ids.items():\n",
    "            all_found = True\n",
    "            for piece in team_name.split():\n",
    "                if piece == 'Wolves':\n",
    "                    piece = 'Wolverhampton'\n",
    "                if piece not in name:\n",
    "                    all_found = False\n",
    "            if all_found:\n",
    "                return name\n",
    "\n",
    "    for i in range(len(odds_data)):\n",
    "        home_api_id = get_api_id(odds_data.at[i, 'HomeTeam'])\n",
    "        away_api_id = get_api_id(odds_data.at[i, 'AwayTeam'])\n",
    "        odds_data.loc[i, 'away_team_api_id'] = str(team_api_ids[home_api_id])\n",
    "        odds_data.loc[i, 'home_team_api_id'] = str(team_api_ids[away_api_id])\n",
    "        \n",
    "    missing_cols = [col for col in desired_cols if col not in odds_data.columns]\n",
    "    for col in missing_cols:\n",
    "        odds_data[col] = np.NaN\n",
    "    odds_data = odds_data[desired_cols]\n",
    "    return odds_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "odds_17_18 = pd.read_csv('17-18_odds.csv')\n",
    "odds_18_19 = pd.read_csv('18-19_odds.csv')\n",
    "\n",
    "odds_17_18 = clean_odds_data(odds_17_18)\n",
    "odds_18_19 = clean_odds_data(odds_18_19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def combine_team_and_match_data(matches):\n",
    "    ### Add blank columns for team attributes to be filled in for each match\n",
    "    for column in list(team_attributes.columns.values):\n",
    "        matches['__home_' + column] = np.nan\n",
    "\n",
    "    for column in list(team_attributes.columns.values):\n",
    "        matches['__away_' + column] = np.nan\n",
    "\n",
    "    ### To assist in filling values later (note the underscores leading __underscoes added above & used here \n",
    "    ### so we don't collide with existing column names)\n",
    "    home_column_indexes = [matches.columns.get_loc('__home_' + col_name) for col_name in team_attributes.columns.values]\n",
    "    away_column_indexes = [matches.columns.get_loc('__away_' + col_name) for col_name in team_attributes.columns.values]\n",
    "\n",
    "    for index, match in matches.iterrows():\n",
    "        ### For each match, we find the home and away team, and add their data to the dataframe\n",
    "        home_team_id = match['home_team_api_id']\n",
    "        away_team_id = match['away_team_api_id']\n",
    "        home_team_atts = team_attributes.loc[team_attributes['team_api_id'] == home_team_id]\n",
    "        away_team_atts = team_attributes.loc[team_attributes['team_api_id'] == away_team_id]    \n",
    "\n",
    "        matches.iloc[index, home_column_indexes] = home_team_atts.values[0]\n",
    "        matches.iloc[index, away_column_indexes] = away_team_atts.values[0]\n",
    "    return matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "combined_odds_17_18 = combine_team_and_match_data(odds_17_18)\n",
    "combined_odds_18_19 = combine_team_and_match_data(odds_18_19)\n",
    "combined_odds = combined_odds_17_18.append(combined_odds_18_19, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Enumerate the columns if they have string values\n",
    "newCol = {}\n",
    "for col in combined_odds.columns.values:\n",
    "    if re.search('Class', col):\n",
    "            enum_dict = { k: v for v, k in dict(enumerate(list(set(combined_odds[col])))).items()}\n",
    "            newCol[col] = combined_odds[col].map(enum_dict)\n",
    "            \n",
    "for colName in newCol.keys():\n",
    "    combined_odds[colName] = newCol[colName]\n",
    "    \n",
    "matches = combined_odds[['B365H', 'B365D', 'B365A', 'BWH', 'BWD', 'BWA', 'IWH', 'IWD', 'IWA', 'LBH', 'LBD', 'LBA', 'PSH', 'PSD', 'PSA', 'WHH', 'WHD', 'WHA', 'SJH', 'SJD', 'SJA', 'VCH', 'VCD', 'VCA', 'GBH', 'GBD', 'GBA', 'BSH', 'BSD', 'BSA', '__home_team_fifa_api_id', '__home_buildUpPlaySpeed', '__home_buildUpPlaySpeedClass', '__home_buildUpPlayDribbling', '__home_buildUpPlayDribblingClass', '__home_buildUpPlayPassing', '__home_buildUpPlayPassingClass', '__home_buildUpPlayPositioningClass', '__home_chanceCreationPassing', '__home_chanceCreationPassingClass', '__home_chanceCreationCrossing', '__home_chanceCreationCrossingClass', '__home_chanceCreationShooting', '__home_chanceCreationShootingClass', '__home_chanceCreationPositioningClass', '__home_defencePressure', '__home_defencePressureClass', '__home_defenceAggression', '__home_defenceAggressionClass', '__home_defenceTeamWidth', '__home_defenceTeamWidthClass', '__home_defenceDefenderLineClass', '__away_team_fifa_api_id', '__away_buildUpPlaySpeed', '__away_buildUpPlaySpeedClass', '__away_buildUpPlayDribbling', '__away_buildUpPlayDribblingClass', '__away_buildUpPlayPassing', '__away_buildUpPlayPassingClass', '__away_buildUpPlayPositioningClass', '__away_chanceCreationPassing', '__away_chanceCreationPassingClass', '__away_chanceCreationCrossing', '__away_chanceCreationCrossingClass', '__away_chanceCreationShooting', '__away_chanceCreationShootingClass', '__away_chanceCreationPositioningClass', '__away_defencePressure', '__away_defencePressureClass', '__away_defenceAggression', '__away_defenceAggressionClass', '__away_defenceTeamWidth', '__away_defenceTeamWidthClass', '__away_defenceDefenderLineClass']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#fill in missing data with na with -1\n",
    "#CHANGE LATER TO BE MORE ROBUST\n",
    "matches = matches.fillna(-1)\n",
    "matches.to_csv('recent_seasons_unnormalized.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Home  Draw  Away\n",
      "0       1     0     0\n",
      "1       0     0     1\n",
      "2       0     0     1\n",
      "3       0     0     1\n",
      "4       1     0     0\n",
      "5       0     1     0\n",
      "6       0     1     0\n",
      "7       1     0     0\n",
      "8       1     0     0\n",
      "9       0     0     1\n",
      "10      0     0     1\n",
      "11      0     0     1\n",
      "12      1     0     0\n",
      "13      1     0     0\n",
      "14      1     0     0\n",
      "15      1     0     0\n",
      "16      0     0     1\n",
      "17      1     0     0\n",
      "18      0     0     1\n",
      "19      0     1     0\n",
      "20      0     0     1\n",
      "21      0     0     1\n",
      "22      0     1     0\n",
      "23      1     0     0\n",
      "24      1     0     0\n",
      "25      0     1     0\n",
      "26      1     0     0\n",
      "27      1     0     0\n",
      "28      0     1     0\n",
      "29      0     1     0\n",
      "..    ...   ...   ...\n",
      "490     1     0     0\n",
      "491     0     0     1\n",
      "492     0     1     0\n",
      "493     0     1     0\n",
      "494     1     0     0\n",
      "495     0     1     0\n",
      "496     0     1     0\n",
      "497     0     1     0\n",
      "498     1     0     0\n",
      "499     1     0     0\n",
      "500     0     1     0\n",
      "501     1     0     0\n",
      "502     1     0     0\n",
      "503     0     1     0\n",
      "504     1     0     0\n",
      "505     0     0     1\n",
      "506     0     0     1\n",
      "507     0     0     1\n",
      "508     0     0     1\n",
      "509     0     0     1\n",
      "510     1     0     0\n",
      "511     1     0     0\n",
      "512     0     0     1\n",
      "513     1     0     0\n",
      "514     1     0     0\n",
      "515     0     0     1\n",
      "516     0     1     0\n",
      "517     1     0     0\n",
      "518     1     0     0\n",
      "519     1     0     0\n",
      "\n",
      "[520 rows x 3 columns] True\n"
     ]
    }
   ],
   "source": [
    "index = range(0, combined_odds.shape[0]) # number rows\n",
    "columns = ['Home', 'Draw', 'Away']\n",
    "new_to_remove = []\n",
    "labels =  pd.DataFrame(index=index, columns=columns)\n",
    "\n",
    "for index, match in combined_odds.iterrows():\n",
    "    if index in combined_odds.index.values:\n",
    "        if int(match['home_team_goal']) > int(match['away_team_goal']):\n",
    "            labels.at[index, 'Home'] = 1\n",
    "        elif int(match['home_team_goal']) == int(match['away_team_goal']):\n",
    "            labels.at[index, 'Draw'] = 1\n",
    "        else:\n",
    "            labels.at[index, 'Away'] = 1\n",
    "    else:\n",
    "        new_to_remove.append(index)\n",
    "        \n",
    "labels = labels.drop(new_to_remove, axis=0)\n",
    "labels = labels.fillna(0)\n",
    "print(labels, labels.shape[0] == combined_odds.shape[0])\n",
    "assert(labels.index.values.all() == matches.index.values.all())\n",
    "labels.to_csv('labels_recent_seasons.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
