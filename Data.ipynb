{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "_cell_guid": "adb0c08c-1a70-dee0-f86e-246efaf5aa35",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sqlite3 as sq\n",
    "import time\n",
    "import math\n",
    "import re\n",
    "from sklearn import preprocessing\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "f18da71b-0594-9e6e-c8a0-81bc6c4479c4"
   },
   "outputs": [],
   "source": [
    "#just reading data\n",
    "con = sq.connect(\"database.sqlite\")\n",
    "team_atts = pd.read_sql_query(\"SELECT * from Team_Attributes\", con)\n",
    "teams = pd.read_sql_query(\"SELECT * from Team\", con)\n",
    "matches = pd.read_sql_query(\"SELECT * from Match\", con)\n",
    "matches = matches[['date', 'season', 'home_team_goal', 'away_team_goal', 'home_team_api_id', 'away_team_api_id', \n",
    "                  'goal', 'shoton', 'shotoff', 'foulcommit', 'card', 'cross', 'corner', 'possession',\n",
    "                  'B365H', 'B365D', 'B365A', 'BWH', 'BWD', 'BWA', 'IWH', 'IWD', 'IWA', 'LBH', 'LBD',\n",
    "                  'LBA', 'PSH', 'PSD', 'PSA', 'WHH', 'WHD', 'WHA', 'SJH', 'SJD', 'SJA', 'VCH', 'VCD',\n",
    "                  'VCA', 'GBH', 'GBD', 'GBA', 'BSH', 'BSD', 'BSA']]\n",
    "\n",
    "attr_dates = pd.DataFrame(columns=['date', 'year', 'month'])\n",
    "attr_dates['date'] = pd.to_datetime(team_atts['date'])\n",
    "attr_dates['year'] = [attr_date.year for attr_date in attr_dates['date']]\n",
    "attr_dates['month'] = [attr_date.month for attr_date in attr_dates['date']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "835340aa-2788-acc0-ecb0-65c4d290ea3c"
   },
   "outputs": [],
   "source": [
    "# print(team_atts.columns.values)\n",
    "\n",
    "### Tasks TODO: \n",
    "### Drop columns that are redundant\n",
    "### Drop rows that are missing too many values\n",
    "### Replace text data such as \"slow, medium, fast\" with number mappings that make sense (e.g. 0, 1, 2) \n",
    "### Normalize all features to be in the range (0, 1): subtract the low value and divide by (high - low)\n",
    "\n",
    "buildUpPlaySpeed = {'Slow': 0, 'Balanced': 1, 'Fast': 2}\n",
    "\n",
    "st = time.time()\n",
    "\n",
    "denom = len(matches.columns.values)\n",
    "\n",
    "\n",
    "### Add blank columns for team attributes to be filled in for each match\n",
    "for column in list(team_atts.columns.values):\n",
    "    matches['__home_' + column] = np.nan\n",
    "    \n",
    "for column in list(team_atts.columns.values):\n",
    "    matches['__away_' + column] = np.nan\n",
    "\n",
    "### To assist in filling values later (note the underscores leading __underscoes added above & used here \n",
    "### so we don't collide with existing column names)\n",
    "home_column_indexes = [matches.columns.get_loc('__home_' + col_name) for col_name in team_atts.columns.values]\n",
    "away_column_indexes = [matches.columns.get_loc('__away_' + col_name) for col_name in team_atts.columns.values]\n",
    "indexes_to_drop = []\n",
    "\n",
    "## Part of experiments described below\n",
    "n_15_none_match = 0\n",
    "n_15_none_team_att = 0\n",
    "\n",
    "for index, match in matches.iterrows():\n",
    "    ### For each match, we find the home and away team for the correct year, and add their data to the \n",
    "    ### dataframe\n",
    "    match_years = [int(year) for year in match['season'].split('/')]\n",
    "    home_team_id = match['home_team_api_id']\n",
    "    away_team_id = match['away_team_api_id']\n",
    "    home_team_atts = team_atts.loc[team_atts['team_api_id'] == home_team_id]\n",
    "    away_team_atts = team_atts.loc[team_atts['team_api_id'] == away_team_id]\n",
    "    \n",
    "    def date_matches(match_years):\n",
    "        return (((attr_dates['year'] == match_years[0]) & (attr_dates['month'] >= 7)) | \n",
    "                ((attr_dates['year'] == match_years[1]) & (attr_dates['month'] < 7)))\n",
    "\n",
    "    home_team_att = home_team_atts.loc[date_matches(match_years)]\n",
    "    away_team_att = away_team_atts.loc[date_matches(match_years)]\n",
    "    \n",
    "    \n",
    "    ### This is just an experiment to determine a threshold for how many values should be 'None'\n",
    "    ### in match data in order for us to drop a row. To drop a row, add its index to \"indexes_to_drop\"\n",
    "    ### if too many values are 'None'\n",
    "    pct_match_none = sum(1 for val in match.values if val is None) / denom\n",
    "    if pct_match_none > 0.15:\n",
    "        n_15_none_match += 1\n",
    "\n",
    "    if not home_team_att.empty and not away_team_att.empty:\n",
    "        matches.iloc[index, home_column_indexes] = home_team_att.values[0]\n",
    "        matches.iloc[index, away_column_indexes] = away_team_att.values[0]\n",
    "        \n",
    "        \n",
    "        ### This is just an experiment to determine a threshold for how many values should be 'None'\n",
    "        ### in team attribute data in order for us to drop a row. To drop a row, add its index to \"indexes_to_drop\"\n",
    "        ### if too many values are 'None'\n",
    "        pct_home_none = sum(1 for val in home_team_att.values[0] if val is None) / len(home_team_att.values)\n",
    "        pct_away_none = sum(1 for val in away_team_att.values[0] if val is None) / len(away_team_att.values)\n",
    "        if pct_home_none > 0.15 or pct_away_none > 0.3:\n",
    "            n_15_none_team_att += 1\n",
    "        \n",
    "    else:\n",
    "        indexes_to_drop.append(index)\n",
    "\n",
    "### Part of our experiments\n",
    "n_rows = index\n",
    "print('total input rows:', n_rows)\n",
    "print('num lacking any team attribute data:', len(indexes_to_drop))\n",
    "print('num where >15% of team data is None:', n_15_none_match)\n",
    "print('num where >15% of team attribute data is None:', n_15_none_team_att)\n",
    "\n",
    "matches = matches.drop(indexes_to_drop, axis=0) ### Drops rows that lack too much data\n",
    "\n",
    "print('Took {0:.2f} seconds.'.format(time.time() - st))\n",
    "matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(matches.columns.values, len(matches.columns.values))\n",
    "\n",
    "#drop first 13 of matches:\n",
    "matches = matches.drop(['date', 'season', 'home_team_goal', 'away_team_goal' ,'home_team_api_id',\n",
    " 'away_team_api_id', 'goal', 'shoton' ,'shotoff', 'foulcommit', 'card', 'cross',\n",
    " 'corner', 'possession'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(matches.columns.values, len(matches.columns.values))\n",
    "print(matches)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Enumerate the columns if they have string values\n",
    "newCol = {}\n",
    "for col in matches.columns.values:\n",
    "    if re.search('Class', col):\n",
    "            #print(col, matches[col])\n",
    "            #enum_dict = dict(enumerate(list(set(matches[col]))))\n",
    "            enum_dict = { k: v for v, k in dict(enumerate(list(set(matches[col])))).items()}\n",
    "            #print(col, enum_dict)\n",
    "            #print(matches[col])\n",
    "            newCol[col] = matches[col].map(enum_dict)\n",
    "#print(newCol['__home_buildUpPlaySpeedClass'])\n",
    "for colName in newCol.keys():\n",
    "    matches[colName] = newCol[colName]\n",
    "matches.to_csv('data_enumerated.csv')\n",
    "matches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# __home_buildUpPlaySpeedClass {'Balanced': 0, 'Slow': 1, 'Fast': 2}\n",
    "# __home_buildUpPlayDribblingClass {'Normal': 0, 'Little': 1, 'Lots': 2}\n",
    "# __home_buildUpPlayPassingClass {'Mixed': 0, 'Long': 1, 'Short': 2}\n",
    "# __home_buildUpPlayPositioningClass {'Organised': 0, 'Free Form': 1}\n",
    "# __home_chanceCreationPassingClass {'Risky': 0, 'Normal': 1, 'Safe': 2}\n",
    "# __home_chanceCreationCrossingClass {'Normal': 0, 'Little': 1, 'Lots': 2}\n",
    "# __home_chanceCreationShootingClass {'Normal': 0, 'Little': 1, 'Lots': 2}\n",
    "# __home_chanceCreationPositioningClass {'Organised': 0, 'Free Form': 1}\n",
    "# __home_defencePressureClass {'Deep': 0, 'Medium': 1, 'High': 2}\n",
    "# __home_defenceAggressionClass {'Double': 0, 'Contain': 1, 'Press': 2}\n",
    "# __home_defenceTeamWidthClass {'Normal': 0, 'Wide': 1, 'Narrow': 2}\n",
    "# __home_defenceDefenderLineClass {'Offside Trap': 0, 'Cover': 1}\n",
    "# __away_buildUpPlaySpeedClass {'Balanced': 0, 'Slow': 1, 'Fast': 2}\n",
    "# __away_buildUpPlayDribblingClass {'Normal': 0, 'Little': 1, 'Lots': 2}\n",
    "# __away_buildUpPlayPassingClass {'Mixed': 0, 'Long': 1, 'Short': 2}\n",
    "# __away_buildUpPlayPositioningClass {'Organised': 0, 'Free Form': 1}\n",
    "# __away_chanceCreationPassingClass {'Normal': 0, 'Risky': 1, 'Safe': 2}\n",
    "# __away_chanceCreationCrossingClass {'Normal': 0, 'Little': 1, 'Lots': 2}\n",
    "# __away_chanceCreationShootingClass {'Normal': 0, 'Little': 1, 'Lots': 2}\n",
    "# __away_chanceCreationPositioningClass {'Organised': 0, 'Free Form': 1}\n",
    "# __away_defencePressureClass {'Deep': 0, 'Medium': 1, 'High': 2}\n",
    "# __away_defenceAggressionClass {'Double': 0, 'Contain': 1, 'Press': 2}\n",
    "# __away_defenceTeamWidthClass {'Normal': 0, 'Wide': 1, 'Narrow': 2}\n",
    "# __away_defenceDefenderLineClass {'Offside Trap': 0, 'Cover': 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get rid of cols missing betting odds\n",
    "to_remove = []\n",
    "columns = matches.columns.values[:30]\n",
    "for index, match in matches.iterrows():\n",
    "    n_missing = 0\n",
    "    for col in columns: \n",
    "        if pd.isnull(match[col]):\n",
    "            n_missing += 1\n",
    "    if n_missing >= 15:\n",
    "        to_remove.append(index)\n",
    "matches = matches.drop(to_remove, axis=0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_to_remove = []\n",
    "for col in matches.columns.values:\n",
    "    if re.search('date', col):\n",
    "        new_to_remove.append(col)\n",
    "matches = matches.drop(new_to_remove, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# #TODO: Normalize columns\n",
    "# ###################\n",
    "# for \n",
    "#     x = df[['score']].values.astype(float)\n",
    "\n",
    "#     # Create a minimum and maximum processor object\n",
    "#     min_max_scaler = preprocessing.MinMaxScaler()\n",
    "\n",
    "#     # Create an object to transform the data to fit minmax processor\n",
    "#     x_scaled = min_max_scaler.fit_transform(x)\n",
    "\n",
    "#     # Run the normalizer on the dataframe\n",
    "#     df_normalized = pd.DataFrame(x_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "matches.to_csv(\"full_betting_odds.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fill in missing data with na with -1\n",
    "#CHANGE LATER TO BE MORE ROBUST\n",
    "matches = matches.fillna(-1)\n",
    "matches.to_csv('negative_one_fill.csv')\n",
    "matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get labels\n",
    "new_to_remove = []\n",
    "og = pd.read_sql_query(\"SELECT * from Match\", con)\n",
    "index = range(0,og.shape[0]) # number rows\n",
    "columns = ['Home', 'Draw', 'Away']\n",
    "labels =  pd.DataFrame(index=index, columns=columns)\n",
    "print(index, matches.index.values)\n",
    "for index, match in og.iterrows():\n",
    "    assert(index in matches.index.values):\n",
    "        if match['home_team_goal'] > match['away_team_goal']:\n",
    "            labels.at[index, 'Home'] = 1\n",
    "        elif match['home_team_goal'] == match['away_team_goal']:\n",
    "            labels.at[index, 'Draw'] = 1\n",
    "        else:\n",
    "            labels.at[index, 'Away'] = 1\n",
    "    else:\n",
    "        new_to_remove.append(index)\n",
    "labels = labels.drop(new_to_remove, axis=0)\n",
    "labels = labels.fillna(0)\n",
    "print(labels, labels.shape[0] == matches.shape[0])\n",
    "labels.to_csv('labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#shuffle match rows so split tables are randomized\n",
    "# matches = matches.reindex(np.random.permutation(matches.index))\n",
    "\n",
    "matches.to_csv('cleaned_data.csv')\n",
    "#split match data into training, validation, and test sets\n",
    "# m_train = matches.iloc[:17861]\n",
    "# m_valid = matches.iloc[17861:21108]\n",
    "# m_test = matches.iloc[21108:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "_change_revision": 0,
  "_is_fork": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
